#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPTæ§åˆ¶å™¨æ¨¡å—
åŠŸèƒ½ï¼šä¸GPT-4O APIäº¤äº’ï¼Œåˆ†ææˆªå›¾å¹¶ç”Ÿæˆæ“ä½œæŒ‡ä»¤
"""

import asyncio
import base64
import json
import logging
import os
import time
from typing import Dict, List, Optional, Any
from openai import OpenAI  # æ›´æ”¹ä¸ºåŒæ­¥å®¢æˆ·ç«¯
from PIL import Image
import io

logger = logging.getLogger(__name__)

class GPTController:
    """GPTæ§åˆ¶å™¨ç±»"""
    
    def __init__(self, api_key: str, base_url: Optional[str] = None):
        # ç®€åŒ–å®¢æˆ·ç«¯åˆå§‹åŒ–ï¼Œåªä¼ é€’å¿…è¦å‚æ•°
        client_kwargs = {"api_key": api_key}
        
        # åªæœ‰åœ¨base_urlå­˜åœ¨ä¸”æœ‰æ•ˆæ—¶æ‰æ·»åŠ 
        if base_url and base_url.strip():
            # æ¸…ç†base_urlæ ¼å¼
            if base_url.endswith('/chat/completions'):
                base_url = base_url.replace('/chat/completions', '')
            if base_url.endswith('/v1'):
                base_url = base_url
            elif not base_url.endswith('/v1'):
                base_url = base_url.rstrip('/') + '/v1'
            
            client_kwargs["base_url"] = base_url
            logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰API base_url: {base_url}")
        
        try:
            self.client = OpenAI(**client_kwargs)
            logger.info("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            # å°è¯•ä¸ä½¿ç”¨base_urlçš„åŸºç¡€åˆå§‹åŒ–
            self.client = OpenAI(api_key=api_key)
            logger.info("ä½¿ç”¨åŸºç¡€APIåœ°å€åˆå§‹åŒ–")
            
        self.conversation_history = []
        self.analysis_cache = {}
        self.max_history_length = 10
        
        # ç³»ç»Ÿæç¤ºè¯ - ä¸“æ³¨äºé¡¹ç›®åŠŸèƒ½å®Œæˆçš„äº§å“å¯¼å‘
        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„CURSOR IDEè‡ªåŠ¨åŒ–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æCURSORç•Œé¢çš„æˆªå›¾ï¼Œè¯†åˆ«å½“å‰çŠ¶æ€ï¼Œå¹¶æä¾›å‡†ç¡®çš„æ“ä½œæŒ‡ä»¤ã€‚ä½ çš„ç›®æ ‡æ˜¯å¸®åŠ©å¿«é€Ÿå®Œæˆæ•´ä¸ªé¡¹ç›®çš„ä¸»è¦åŠŸèƒ½ï¼Œè€Œä¸æ˜¯çº ç»“äºæŠ€æœ¯ç»†èŠ‚ã€‚
**æ ¸å¿ƒåŸåˆ™ï¼šå…ˆåšèƒ½ç”¨ï¼Œå†åšå®Œç¾**
ä½ éœ€è¦è¯†åˆ«ä»¥ä¸‹æƒ…å†µå¹¶æä¾›ç›¸åº”çš„æ“ä½œï¼š

1. **ç­‰å¾…è¾“å…¥çŠ¶æ€**ï¼š
   - CURSORæ˜¾ç¤º"waiting for input"ã€"continue?"ã€"please confirm"ç­‰æç¤º
   - å¯¹è¯æ¡†ä¸­æœ‰è¾“å…¥æ¡†ç­‰å¾…ç”¨æˆ·è¾“å…¥
   - éœ€è¦ç”¨æˆ·ç¡®è®¤æŸä¸ªæ“ä½œ

2. **ä»£ç å®Œæˆå’Œå®¡æŸ¥çŠ¶æ€**ï¼š
   - çœ‹åˆ°"Review changes"ã€"ä»£ç å®Œæˆ"ã€"å®ç°å®Œæˆ"ç­‰å­—æ ·
   - ä»£ç ä¿®æ”¹æˆ–å®ç°å·²ç»å®Œæˆï¼Œéœ€è¦è¿›è¡Œå®¡æŸ¥å’Œåé¦ˆ
   - æ­¤æ—¶åº”è¯¥**è¾“å…¥æ–‡æœ¬è¿›è¡Œä»£ç å®¡æŸ¥å’Œè´¨é‡è¯„ä¼°**ï¼Œè€Œä¸æ˜¯ç‚¹å‡»æŒ‰é’®
   - è¾“å…¥å†…å®¹åº”åŒ…æ‹¬ï¼šä¸‹ä¸€æ­¥å»ºè®®ç­‰

ä½ éœ€è¦è¯†åˆ«CURSORå½“å‰çŠ¶æ€å¹¶æ¨åŠ¨é¡¹ç›®è¿›å±•ï¼š

1. **åŠŸèƒ½å¼€å‘çŠ¶æ€**ï¼š
   - å½“çœ‹åˆ°ä»£ç å®Œæˆã€Review changesã€å®ç°å®Œæˆç­‰ä¿¡å·æ—¶
   - ç«‹å³æ¨åŠ¨ä¸‹ä¸€ä¸ªåŠŸèƒ½çš„å¼€å‘
   - è¾“å…¥æŒ‡ä»¤ï¼šç»§ç»­å¼€å‘ä¸‹ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼Œä¸è¦åœç•™åœ¨ç»†èŠ‚ä¼˜åŒ–

2. **é”™è¯¯å¤„ç†çŠ¶æ€**ï¼š
   - é‡åˆ°é”™è¯¯æ—¶ï¼Œå¿«é€Ÿæ‰¾åˆ°è§£å†³æ–¹æ¡ˆ
   - ä¼˜å…ˆé€‰æ‹©æœ€ç®€å•ã€æœ€ç›´æ¥çš„ä¿®å¤æ–¹æ³•
   - è¾“å…¥æŒ‡ä»¤ï¼šå¿«é€Ÿä¿®å¤è¿™ä¸ªé—®é¢˜ï¼Œä½¿ç”¨æœ€ç®€å•çš„æ–¹æ³•ï¼Œç„¶åç»§ç»­å¼€å‘ä¸»è¦åŠŸèƒ½

3. **å¡ä½çŠ¶æ€**ï¼š
   - å¦‚æœå¼€å‘åœæ»ï¼Œç«‹å³æ¨åŠ¨ç»§ç»­
   - è¾“å…¥æŒ‡ä»¤ï¼šè·³è¿‡è¿™ä¸ªç»†èŠ‚é—®é¢˜ï¼Œå…ˆå®Œæˆæ ¸å¿ƒåŠŸèƒ½ï¼Œåç»­å†ä¼˜åŒ–

**æŒ‡ä»¤ç”ŸæˆåŸåˆ™**ï¼š
- **ç›®æ ‡å¯¼å‘**ï¼šæ¯ä¸ªæŒ‡ä»¤éƒ½è¦æ¨åŠ¨é¡¹ç›®æœç€"èƒ½ç”¨"çš„æ–¹å‘å‰è¿›
- **ç®€å•æœ‰æ•ˆ**ï¼šé€‰æ‹©æœ€ç›´æ¥çš„è§£å†³æ–¹æ¡ˆï¼Œé¿å…è¿‡åº¦è®¾è®¡
- **åŠŸèƒ½ä¼˜å…ˆ**ï¼šä¼˜å…ˆå®Œæˆä¸»è¦åŠŸèƒ½ï¼Œç»†èŠ‚åç»­ä¼˜åŒ–
- **å¿«é€Ÿè¿­ä»£**ï¼šå¿«é€Ÿå®ç°åŸºç¡€ç‰ˆæœ¬ï¼Œç„¶åé€æ­¥æ”¹è¿›

**è¾“å…¥å†…å®¹ç¤ºä¾‹**ï¼š
- "å¾ˆå¥½ï¼è¿™ä¸ªåŠŸèƒ½å·²ç»åŸºæœ¬å®Œæˆäº†ã€‚ç°åœ¨è®©æˆ‘ä»¬å¿«é€Ÿå®ç°ä¸‹ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼š[å…·ä½“åŠŸèƒ½åç§°]ã€‚å…ˆåšä¸€ä¸ªç®€å•èƒ½ç”¨çš„ç‰ˆæœ¬ã€‚"
- "è¿™ä¸ªé”™è¯¯ä¸æ˜¯å…³é”®é—®é¢˜ï¼Œæˆ‘ä»¬ç”¨æœ€ç®€å•çš„æ–¹æ³•ä¿®å¤ï¼š[ç®€å•è§£å†³æ–¹æ¡ˆ]ã€‚ç„¶åç»§ç»­å¼€å‘ä¸»è¦åŠŸèƒ½ã€‚"
- "å½“å‰è¿›å±•è‰¯å¥½ï¼Œè®©æˆ‘ä»¬ç»§ç»­æ¨è¿›é¡¹ç›®ã€‚ä¸‹ä¸€æ­¥éœ€è¦å®ç°ï¼š[ä¸‹ä¸€ä¸ªåŠŸèƒ½]ã€‚ç”¨æœ€ç›´æ¥çš„æ–¹æ³•å®ç°ã€‚"

å¯¹äºæ¯ç§æƒ…å†µï¼Œæä¾›JSONæ ¼å¼çš„æ“ä½œæŒ‡ä»¤ï¼š

```json
{
    "action_type": "type",
    "target": "chat_input",
    "value": "æ¨åŠ¨é¡¹ç›®è¿›å±•çš„å…·ä½“æŒ‡ä»¤",
    "confidence": 0.9,
    "reasoning": "æ¨åŠ¨é¡¹ç›®åŠŸèƒ½å®Œæˆ"
}
```

**è®°ä½ï¼šæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¿«é€Ÿæ­å»ºèµ·æ•´ä¸ªç¨‹åºå¹¶ç¡®ä¿èƒ½ç”¨ï¼Œç»†èŠ‚ä¼˜åŒ–ç•™åˆ°åé¢ï¼**
"""
    
    def analyze_situation(self, screenshot: Image.Image, context: str) -> Dict[str, Any]:
        """åˆ†æå½“å‰æƒ…å†µå¹¶ç”Ÿæˆæ“ä½œæŒ‡ä»¤"""
        try:
            # å°†æˆªå›¾è½¬æ¢ä¸ºbase64
            screenshot_base64 = self.image_to_base64(screenshot)
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "system", 
                    "content": self.system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"åˆ†æè¿™ä¸ªCURSOR IDEæˆªå›¾çš„çŠ¶æ€ã€‚ä¸Šä¸‹æ–‡ï¼š{context}\n\nè¯·æä¾›è¯¦ç»†çš„åˆ†æå’Œæ“ä½œå»ºè®®ã€‚"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{screenshot_base64}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ]
            
            # æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘å‡ è½®ï¼‰
            messages.extend(self.conversation_history[-4:])
            
            # è°ƒç”¨GPT-4O
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=1000,
                temperature=0.1  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„ç»“æœ
            )
            
            # è§£æå“åº”
            response_text = response.choices[0].message.content
            logger.info(f"GPTåˆ†æç»“æœ: {response_text[:200]}...")
            
            # å°è¯•æå–JSONæ“ä½œæŒ‡ä»¤
            action_data = self.extract_action_from_response(response_text)
            
            # æ›´æ–°å¯¹è¯å†å²
            self.update_conversation_history(context, response_text)
            
            return {
                "analysis": response_text,
                "action": action_data,
                "timestamp": time.time(),
                "context": context
            }
            
        except Exception as e:
            logger.error(f"GPTåˆ†ææ—¶å‡ºé”™: {e}")
            return {
                "analysis": f"åˆ†æå¤±è´¥: {str(e)}",
                "action": {
                    "action_type": "wait",
                    "target": "error_recovery",
                    "value": None,
                    "confidence": 0.0,
                    "reasoning": "åˆ†æå‡ºé”™ï¼Œé€‰æ‹©ç­‰å¾…ç­–ç•¥"
                },
                "timestamp": time.time(),
                "context": context
            }
    
    def extract_action_from_response(self, response_text: str) -> Dict[str, Any]:
        """ä»GPTå“åº”ä¸­æå–æ“ä½œæŒ‡ä»¤"""
        try:
            # å°è¯•æ‰¾åˆ°JSONå—
            import re
            json_pattern = r'```json\s*(.*?)\s*```'
            json_match = re.search(json_pattern, response_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1)
                action_data = json.loads(json_str)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ["action_type", "confidence", "reasoning"]
                for field in required_fields:
                    if field not in action_data:
                        action_data[field] = self.get_default_value(field)
                
                return action_data
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•è§£ææ–‡æœ¬æè¿°
            return self.parse_text_action(response_text)
            
        except Exception as e:
            logger.error(f"æå–æ“ä½œæŒ‡ä»¤æ—¶å‡ºé”™: {e}")
            return {
                "action_type": "analyze",
                "target": "unknown",
                "confidence": 0.3,
                "reasoning": "æ— æ³•è§£æGPTå“åº”ï¼Œéœ€è¦é‡æ–°åˆ†æ"
            }
    
    def parse_text_action(self, text: str) -> Dict[str, Any]:
        """è§£ææ–‡æœ¬æè¿°çš„æ“ä½œ"""
        text_lower = text.lower()
        
        # è¯†åˆ«æ“ä½œç±»å‹
        if any(keyword in text_lower for keyword in ["click", "ç‚¹å‡»"]):
            action_type = "click"
        elif any(keyword in text_lower for keyword in ["type", "input", "è¾“å…¥"]):
            action_type = "type"
        elif any(keyword in text_lower for keyword in ["press", "æŒ‰é”®"]):
            action_type = "key_press"
        elif any(keyword in text_lower for keyword in ["wait", "ç­‰å¾…"]):
            action_type = "wait"
        else:
            action_type = "analyze"
        
        return {
            "action_type": action_type,
            "target": "parsed_from_text",
            "confidence": 0.6,
            "reasoning": f"ä»æ–‡æœ¬è§£æå¾—å‡º: {text[:100]}..."
        }
    
    def get_default_value(self, field: str) -> Any:
        """è·å–å­—æ®µçš„é»˜è®¤å€¼"""
        defaults = {
            "action_type": "wait",
            "target": "unknown",
            "value": None,
            "coordinates": None,
            "confidence": 0.5,
            "reasoning": "é»˜è®¤æ“ä½œ",
            "follow_up_actions": []
        }
        return defaults.get(field, None)
    
    def image_to_base64(self, image: Image.Image) -> str:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        try:
            buffer = io.BytesIO()
            image.save(buffer, format='PNG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            return img_base64
        except Exception as e:
            logger.error(f"å›¾åƒè½¬base64æ—¶å‡ºé”™: {e}")
            return ""
    
    def update_conversation_history(self, context: str, response: str):
        """æ›´æ–°å¯¹è¯å†å²"""
        self.conversation_history.append({
            "role": "assistant",
            "content": response
        })
        
        # ä¿æŒå†å²é•¿åº¦é™åˆ¶
        if len(self.conversation_history) > self.max_history_length:
            self.conversation_history = self.conversation_history[-self.max_history_length:]
    
    def analyze_error(self, screenshot: Image.Image, error_text: str) -> Dict[str, Any]:
        """ä¸“é—¨åˆ†æé”™è¯¯æƒ…å†µ"""
        context = f"CURSORå‡ºç°é”™è¯¯ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{error_text}"
        
        messages = [
            {
                "role": "system",
                "content": self.system_prompt + "\n\nç‰¹åˆ«æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªé”™è¯¯åˆ†æè¯·æ±‚ï¼Œè¯·é‡ç‚¹å…³æ³¨é”™è¯¯ä¿®å¤ã€‚"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": f"CURSOR IDEå‡ºç°äº†é”™è¯¯ã€‚è¯·åˆ†ææˆªå›¾ä¸­çš„é”™è¯¯ä¿¡æ¯å¹¶æä¾›ä¿®å¤å»ºè®®ã€‚\né”™è¯¯ä¸Šä¸‹æ–‡ï¼š{error_text}"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{self.image_to_base64(screenshot)}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ]
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=1200,
                temperature=0.1
            )
            
            response_text = response.choices[0].message.content
            action_data = self.extract_action_from_response(response_text)
            
            return {
                "analysis": response_text,
                "action": action_data,
                "error_context": error_text,
                "timestamp": time.time()
            }
            
        except Exception as e:
            logger.error(f"é”™è¯¯åˆ†ææ—¶å‡ºé”™: {e}")
            return {
                "analysis": f"é”™è¯¯åˆ†æå¤±è´¥: {str(e)}",
                "action": {
                    "action_type": "wait",
                    "reasoning": "åˆ†æé”™è¯¯ï¼Œæš‚æ—¶ç­‰å¾…"
                },
                "timestamp": time.time()
            }
    
    def suggest_continuation(self, screenshot: Image.Image, stuck_duration: int) -> Dict[str, Any]:
        """ä¸ºå¡ä½çš„æƒ…å†µæä¾›å»ºè®®"""
        context = f"CURSORå·²ç»å¡ä½ {stuck_duration} ç§’ï¼Œéœ€è¦å¹²é¢„"
        
        messages = [
            {
                "role": "system",
                "content": self.system_prompt + f"\n\nç‰¹åˆ«æ³¨æ„ï¼šCURSORå·²ç»å¡ä½äº†{stuck_duration}ç§’ï¼Œéœ€è¦é‡‡å–è¡ŒåŠ¨è®©å®ƒç»§ç»­å·¥ä½œã€‚"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": f"CURSOR IDEä¼¼ä¹å¡ä½äº†ï¼ˆå·²ç»{stuck_duration}ç§’æ²¡æœ‰å˜åŒ–ï¼‰ã€‚è¯·åˆ†æå½“å‰çŠ¶æ€å¹¶å»ºè®®å¦‚ä½•è®©å®ƒç»§ç»­å·¥ä½œã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{self.image_to_base64(screenshot)}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ]
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=1000,
                temperature=0.2
            )
            
            response_text = response.choices[0].message.content
            action_data = self.extract_action_from_response(response_text)
            
            return {
                "analysis": response_text,
                "action": action_data,
                "stuck_duration": stuck_duration,
                "timestamp": time.time()
            }
            
        except Exception as e:
            logger.error(f"å¡ä½çŠ¶æ€åˆ†ææ—¶å‡ºé”™: {e}")
            return {
                "analysis": f"å¡ä½çŠ¶æ€åˆ†æå¤±è´¥: {str(e)}",
                "action": {
                    "action_type": "key_press",
                    "value": "Escape",
                    "reasoning": "å°è¯•æŒ‰Escapeé”®æ¢å¤"
                },
                "timestamp": time.time()
            }
    
    def clear_conversation_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()
        logger.info("å¯¹è¯å†å²å·²æ¸…ç©º")
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        return {
            "conversation_length": len(self.conversation_history),
            "cache_size": len(self.analysis_cache),
            "last_analysis_time": getattr(self, 'last_analysis_time', 0)
        }
    
    def analyze_completed_task(self, screenshot: Image.Image, completed_text: str, context: str) -> Dict[str, Any]:
        """ä¸“é—¨åˆ†æå®Œæˆçš„ä»»åŠ¡å†…å®¹ï¼Œä»ä¸»åŠ›æ“ç›˜æ‰‹è§’åº¦æä¾›æ·±åº¦åˆ†æå’Œå»ºè®®"""
        try:
            logger.info("ğŸ” å¼€å§‹GPTå®Œæˆä»»åŠ¡åˆ†æ...")
            # å°†æˆªå›¾è½¬æ¢ä¸ºbase64
            screenshot_base64 = self.image_to_base64(screenshot)
            
            # æ„å»ºä¸“é—¨é’ˆå¯¹å®Œæˆä»»åŠ¡çš„ç³»ç»Ÿæç¤ºè¯
            completion_analysis_prompt = """
ä½ æ˜¯ä¸€ä¸ªå…·å¤‡ä¸»åŠ›æ“ç›˜æ‰‹æ€ç»´çš„CURSOR IDEä¸“å®¶åŠ©æ‰‹ã€‚ç°åœ¨éœ€è¦åˆ†æä¸€ä¸ªåˆšåˆšå®Œæˆçš„ç¼–ç¨‹ä»»åŠ¡ã€‚

ä»ä¸»åŠ›æ“ç›˜æ‰‹çš„è§’åº¦ï¼Œä½ éœ€è¦ï¼š
1. **åäººæ€§åˆ†æ**: è¯†åˆ«å®Œæˆå†…å®¹ä¸­å¯èƒ½çš„"è¯±å¤š"é™·é˜±æˆ–è¿‡åº¦ä¹è§‚
2. **æ·±åº¦ä»·å€¼è¯„ä¼°**: å®¢è§‚è¯„ä¼°å®é™…ä»·å€¼ï¼Œé¿å…è¢«è¡¨é¢æˆåŠŸè¿·æƒ‘  
3. **ä¸‹ä¸€æ­¥ç­–ç•¥**: ä»æ“ç›˜æ‰‹è§’åº¦å»ºè®®æœ€ä¼˜åç»­è¡ŒåŠ¨
4. **é£é™©è¯†åˆ«**: æŒ‡å‡ºå¯èƒ½è¢«å¿½è§†çš„æ½œåœ¨é—®é¢˜

è¯·æä¾›ç®€æ´çš„åˆ†æç»“æœï¼ˆä¸è¶…è¿‡500å­—ï¼‰ï¼š

```json
{
    "action_type": "continue_conversation|provide_feedback|suggest_improvements|acknowledge_completion",
    "master_analysis": "ä»ä¸»åŠ›æ“ç›˜æ‰‹è§’åº¦çš„æ·±åº¦åˆ†æ",
    "value_assessment": "å®é™…ä»·å€¼è¯„ä¼°ï¼ˆé¿å…è¢«è¡¨é¢æˆåŠŸè¿·æƒ‘ï¼‰",
    "risk_identification": "æ½œåœ¨é£é™©å’Œé™·é˜±è¯†åˆ«",  
    "next_strategy": "åŸºäºä¸»åŠ›æ€ç»´çš„ä¸‹ä¸€æ­¥ç­–ç•¥",
    "confidence": 0.0-1.0,
    "reasoning": "é€‰æ‹©æ­¤è¡ŒåŠ¨çš„ä¸»åŠ›æ“ç›˜æ‰‹é€»è¾‘"
}
```

é‡è¦åŸåˆ™ï¼š
- ä¿æŒä¸»åŠ›æ“ç›˜æ‰‹çš„å†·é™ç†æ€§ï¼Œä¸è¢«è¡¨é¢æˆåŠŸå†²æ˜å¤´è„‘
- è¯†åˆ«æ•£æˆ·æ€ç»´é™·é˜±ï¼Œæä¾›åäººæ€§çš„æ·±åº¦è§è§£
- å…³æ³¨é•¿æœŸæˆ˜ç•¥ä»·å€¼ï¼Œè€ŒéçŸ­æœŸè¡¨é¢æˆæœ
- æä¾›å…·ä½“å¯è¡Œçš„åç»­è¡ŒåŠ¨å»ºè®®
"""
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "system", 
                    "content": completion_analysis_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"""åˆšåˆšå®Œæˆäº†ä¸€ä¸ªç¼–ç¨‹ä»»åŠ¡ï¼Œè¯·ä»ä¸»åŠ›æ“ç›˜æ‰‹è§’åº¦è¿›è¡Œæ·±åº¦åˆ†æã€‚

ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼š{context}

å®Œæˆå†…å®¹æ–‡æœ¬ï¼š{completed_text[:1000]}

è¯·æä¾›ç®€æ´çš„ä¸»åŠ›æ“ç›˜æ‰‹åˆ†æï¼ˆä¸è¶…è¿‡500å­—ï¼‰ã€‚"""
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{screenshot_base64}",
                                "detail": "low"  # é™ä½å›¾åƒç»†èŠ‚ä»¥åŠ å¿«å¤„ç†
                            }
                        }
                    ]
                }
            ]
            
            logger.info("ğŸ“¡ å‘é€GPT APIè¯·æ±‚...")
            
            # æ·»åŠ è¶…æ—¶è®¾ç½®çš„APIè°ƒç”¨ï¼ˆWindowså…¼å®¹ç‰ˆæœ¬ï¼‰
            import signal
            import functools
            import threading
            import platform
            
            timeout_occurred = False
            timer = None
            
            def timeout_handler():
                nonlocal timeout_occurred
                timeout_occurred = True
                logger.warning("â° GPT APIè°ƒç”¨è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
            
            # Windowsç³»ç»Ÿå…¼å®¹çš„è¶…æ—¶å¤„ç†
            if platform.system() == "Windows":
                # åœ¨Windowsä¸Šä½¿ç”¨Timer
                timer = threading.Timer(30.0, timeout_handler)
                timer.start()
            else:
                # åœ¨Unixç³»ç»Ÿä¸Šä½¿ç”¨SIGALRM
                def signal_timeout_handler(signum, frame):
                    raise TimeoutError("GPT APIè°ƒç”¨è¶…æ—¶")
                signal.signal(signal.SIGALRM, signal_timeout_handler)
                signal.alarm(30)
            
            try:
                # è°ƒç”¨GPT-4Oè¿›è¡Œä¸“é—¨çš„å®Œæˆä»»åŠ¡åˆ†æ
                response = self.client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    max_tokens=800,  # å‡å°‘tokenæ•°é‡åŠ å¿«å“åº”
                    temperature=0.2,  # æ›´ä½æ¸©åº¦ä»¥è·å¾—æ›´ç†æ€§çš„åˆ†æ
                    timeout=25  # 25ç§’è¶…æ—¶
                )
                
                # å–æ¶ˆè¶…æ—¶
                if timer:
                    timer.cancel()
                elif platform.system() != "Windows":
                    signal.alarm(0)
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                if timeout_occurred:
                    logger.error("â° GPT APIè°ƒç”¨è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                    return self._get_timeout_fallback_analysis(context, completed_text)
                
                logger.info("âœ… GPT APIå“åº”æˆåŠŸ")
                
            except TimeoutError:
                # å–æ¶ˆè¶…æ—¶
                if timer:
                    timer.cancel()
                elif platform.system() != "Windows":
                    signal.alarm(0)
                logger.error("â° GPT APIè°ƒç”¨è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                return self._get_timeout_fallback_analysis(context, completed_text)
            except Exception as api_error:
                # å–æ¶ˆè¶…æ—¶
                if timer:
                    timer.cancel()
                elif platform.system() != "Windows":
                    signal.alarm(0)
                logger.error(f"âŒ GPT APIè°ƒç”¨å¤±è´¥: {api_error}")
                return self._get_api_error_fallback_analysis(context, completed_text, str(api_error))
            
            # è§£æå“åº”
            response_text = response.choices[0].message.content
            logger.info(f"ğŸ“ GPTå®Œæˆä»»åŠ¡åˆ†æ: {response_text[:300]}...")
            
            # å°è¯•æå–JSONåˆ†æç»“æœ
            analysis_data = self.extract_completion_analysis(response_text)
            
            # æ›´æ–°å¯¹è¯å†å²
            self.update_conversation_history(f"ä»»åŠ¡å®Œæˆåˆ†æ: {context}", response_text)
            
            return {
                "analysis": response_text,
                "action": analysis_data,
                "master_analysis": analysis_data.get("master_analysis", ""),
                "value_assessment": analysis_data.get("value_assessment", ""),
                "risk_identification": analysis_data.get("risk_identification", ""),
                "next_strategy": analysis_data.get("next_strategy", ""),
                "timestamp": time.time(),
                "context": context,
                "completion_text": completed_text
            }
            
        except Exception as e:
            logger.error(f"âŒ å®Œæˆä»»åŠ¡åˆ†ææ—¶å‡ºé”™: {e}")
            return self._get_general_error_fallback_analysis(context, completed_text, str(e))
    
    def _get_timeout_fallback_analysis(self, context: str, completed_text: str) -> Dict[str, Any]:
        """è¶…æ—¶åçš„å¤‡ç”¨åˆ†æ"""
        return {
            "analysis": "â° GPTåˆ†æè¶…æ—¶ï¼Œä½¿ç”¨æœ¬åœ°å¤‡ç”¨åˆ†æ",
            "action": {
                "action_type": "provide_feedback",
                "master_analysis": "æ£€æµ‹åˆ°ä»»åŠ¡å®Œæˆï¼Œä½†ç½‘ç»œåˆ†æè¶…æ—¶ã€‚ä»ä¸»åŠ›è§’åº¦å»ºè®®ï¼šå…ˆéªŒè¯åŸºç¡€åŠŸèƒ½æ˜¯å¦æ­£å¸¸",
                "value_assessment": "éœ€è¦æ‰‹åŠ¨éªŒè¯å®Œæˆè´¨é‡ï¼Œé¿å…è¢«è¡¨é¢å®Œæˆè¿·æƒ‘",
                "risk_identification": "ç½‘ç»œåˆ†æä¸å¯ç”¨ï¼Œå­˜åœ¨ç›²ç‚¹é£é™©",
                "next_strategy": "ä¼˜å…ˆè¿›è¡Œæœ¬åœ°æµ‹è¯•ï¼Œç¡®è®¤åŸºç¡€åŠŸèƒ½æ— è¯¯åå†è€ƒè™‘ä¸‹ä¸€æ­¥",
                "confidence": 0.6,
                "reasoning": "ç½‘ç»œè¶…æ—¶ï¼Œé‡‡ç”¨ä¿å®ˆçš„ä¸»åŠ›ç­–ç•¥"
            },
            "timestamp": time.time(),
            "context": context,
            "fallback_reason": "api_timeout"
        }
    
    def _get_api_error_fallback_analysis(self, context: str, completed_text: str, error_msg: str) -> Dict[str, Any]:
        """APIé”™è¯¯åçš„å¤‡ç”¨åˆ†æ"""
        return {
            "analysis": f"âŒ GPT APIé”™è¯¯ï¼Œä½¿ç”¨æœ¬åœ°å¤‡ç”¨åˆ†æ: {error_msg}",
            "action": {
                "action_type": "provide_feedback", 
                "master_analysis": "æ£€æµ‹åˆ°ä»»åŠ¡å®Œæˆï¼Œä½†APIåˆ†æå¤±è´¥ã€‚ä»ä¸»åŠ›è§’åº¦ï¼šè¿™ç§æƒ…å†µä¸‹æ›´è¦ä¿æŒç†æ€§",
                "value_assessment": "æ— æ³•ä½¿ç”¨AIæ·±åº¦åˆ†æï¼Œéœ€è¦ä¾é ä¸»åŠ›ç»éªŒæ‰‹åŠ¨è¯„ä¼°ä»·å€¼",
                "risk_identification": "åˆ†æå·¥å…·å¤±æ•ˆï¼Œå­˜åœ¨åˆ¤æ–­ç›²åŒºé£é™©",
                "next_strategy": "é‡‡ç”¨æœ€ä¿å®ˆç­–ç•¥ï¼šé€æ­¥éªŒè¯ï¼Œå°æ­¥è¯•é”™",
                "confidence": 0.5,
                "reasoning": "APIå¤±æ•ˆæ—¶çš„ä¸»åŠ›åº”æ€¥ç­–ç•¥"
            },
            "timestamp": time.time(),
            "context": context,
            "fallback_reason": "api_error"
        }
    
    def _get_general_error_fallback_analysis(self, context: str, completed_text: str, error_msg: str) -> Dict[str, Any]:
        """é€šç”¨é”™è¯¯åçš„å¤‡ç”¨åˆ†æ"""
        return {
            "analysis": f"ğŸ› ï¸ åˆ†æç³»ç»Ÿé‡åˆ°é—®é¢˜ï¼Œä½¿ç”¨æœ¬åœ°å¤‡ç”¨åˆ†æ: {error_msg}",
            "action": {
                "action_type": "acknowledge_completion",
                "master_analysis": "ç³»ç»Ÿæ£€æµ‹åˆ°ä»»åŠ¡å®Œæˆã€‚è™½ç„¶æ·±åº¦åˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œä½†ä¸»åŠ›æ€ç»´å‘Šè¯‰æˆ‘ä»¬è¦ä¿æŒå†·é™",
                "value_assessment": "éœ€è¦æ‰‹åŠ¨éªŒè¯å®Œæˆè´¨é‡å’Œå®é™…ä»·å€¼",
                "risk_identification": "åˆ†æç³»ç»Ÿå¼‚å¸¸ï¼Œå­˜åœ¨åˆ¤æ–­é£é™©",
                "next_strategy": "ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ï¼šä»£ç å®¡æŸ¥ã€æ‰‹åŠ¨æµ‹è¯•ã€é€æ­¥éªŒè¯",
                "confidence": 0.4,
                "reasoning": "ç³»ç»Ÿå¼‚å¸¸æ—¶çš„ä¸»åŠ›ä¿å®ˆç­–ç•¥"
            },
            "timestamp": time.time(),
            "context": context,
            "fallback_reason": "system_error"
        }
    
    def extract_completion_analysis(self, response_text: str) -> Dict[str, Any]:
        """ä»GPTå“åº”ä¸­æå–å®Œæˆä»»åŠ¡åˆ†æç»“æœ"""
        try:
            # å°è¯•æ‰¾åˆ°JSONå—
            import re
            json_pattern = r'```json\s*(.*?)\s*```'
            json_match = re.search(json_pattern, response_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1)
                analysis_data = json.loads(json_str)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ["action_type", "confidence", "reasoning"]
                for field in required_fields:
                    if field not in analysis_data:
                        analysis_data[field] = self.get_completion_default_value(field)
                
                return analysis_data
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼ŒåŸºäºå…³é”®è¯ç”Ÿæˆåˆ†æ
            return self.parse_completion_text_analysis(response_text)
            
        except Exception as e:
            logger.error(f"æå–å®Œæˆåˆ†ææ—¶å‡ºé”™: {e}")
            return {
                "action_type": "provide_feedback",
                "master_analysis": "ä»æ–‡æœ¬ä¸­è§£æçš„ä¸»åŠ›åˆ†æ",
                "confidence": 0.6,
                "reasoning": f"è§£æå®Œæˆåˆ†æï¼ŒåŸºäºæ–‡æœ¬å†…å®¹: {response_text[:200]}..."
            }
    
    def parse_completion_text_analysis(self, text: str) -> Dict[str, Any]:
        """è§£ææ–‡æœ¬å½¢å¼çš„å®Œæˆåˆ†æ"""
        text_lower = text.lower()
        
        # è¯†åˆ«è¡ŒåŠ¨ç±»å‹
        if any(keyword in text_lower for keyword in ["ç»§ç»­å¯¹è¯", "continue", "discuss", "äº¤æµ"]):
            action_type = "continue_conversation"
        elif any(keyword in text_lower for keyword in ["æ”¹è¿›", "improve", "optimize", "enhance"]):
            action_type = "suggest_improvements"
        elif any(keyword in text_lower for keyword in ["åé¦ˆ", "feedback", "è¯„ä»·"]):
            action_type = "provide_feedback"
        else:
            action_type = "acknowledge_completion"
        
        return {
            "action_type": action_type,
            "master_analysis": f"åŸºäºä¸»åŠ›æ“ç›˜æ‰‹æ€ç»´çš„åˆ†æ: {text[:300]}...",
            "confidence": 0.7,
            "reasoning": f"ä»æ–‡æœ¬åˆ†æå¾—å‡ºçš„ä¸»åŠ›è§†è§’å»ºè®®"
        }
    
    def get_completion_default_value(self, field: str) -> Any:
        """è·å–å®Œæˆåˆ†æå­—æ®µçš„é»˜è®¤å€¼"""
        defaults = {
            "action_type": "acknowledge_completion",
            "master_analysis": "ä»»åŠ¡å®Œæˆï¼Œéœ€è¦ä»ä¸»åŠ›è§’åº¦è¿›ä¸€æ­¥åˆ†æ",
            "value_assessment": "åˆæ­¥è¯„ä¼°æ˜¾ç¤ºä»»åŠ¡å·²å®Œæˆï¼Œéœ€æ·±å…¥éªŒè¯å®é™…ä»·å€¼",
            "risk_identification": "éœ€è¦è¯†åˆ«æ½œåœ¨é£é™©å’Œç›²ç‚¹",
            "next_strategy": "å»ºè®®è¿›è¡Œå®æˆ˜æµ‹è¯•ä»¥éªŒè¯çœŸå®æ•ˆæœ",
            "confidence": 0.7,
            "reasoning": "åŸºäºä¸»åŠ›æ“ç›˜æ‰‹ç»éªŒçš„ä¿å®ˆåˆ¤æ–­",
            "conversation_trigger": "å»ºè®®ä¸»åŠ¨å¯¹è¯ä»¥è·å–æ›´å¤šä¿¡æ¯"
        }
        return defaults.get(field, None)
    
    async def analyze_cursor_state(self, screenshot: Image.Image, extracted_text: str, context: str = "") -> Dict[str, Any]:
        """å¼‚æ­¥åˆ†æCURSORçŠ¶æ€ - ä¿æŒå‘åå…¼å®¹æ€§"""
        try:
            return self.analyze_situation(screenshot, f"{context}\nå½“å‰æ–‡æœ¬å†…å®¹: {extracted_text}")
        except Exception as e:
            logger.error(f"å¼‚æ­¥CURSORçŠ¶æ€åˆ†æå¤±è´¥: {e}")
            return {
                "analysis": f"å¼‚æ­¥åˆ†æå¤±è´¥: {str(e)}",
                "action": {
                    "action_type": "wait",
                    "confidence": 0.0,
                    "reasoning": "å¼‚æ­¥åˆ†æå‡ºé”™ï¼Œç­‰å¾…æ¢å¤"
                }
            }

    def analyze_as_product_manager(self, screenshot: Image.Image, cursor_reply: str, 
                                 project_context: str, conversation_history: str, 
                                 current_stage: str) -> str:
        """ä½œä¸ºäº§å“ç»ç†åˆ†æCURSORå›å¤å¹¶ç”Ÿæˆå¯¹è¯å›å¤"""
        try:
            # äº§å“å¯¼å‘çš„å¼€å‘æ¨è¿›è€…ç³»ç»Ÿæç¤ºè¯
            product_manager_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“æ³¨äºäº§å“åŠŸèƒ½å¿«é€Ÿå®ç°çš„å¼€å‘æ¨è¿›è€…ã€‚ä½ çš„ä½¿å‘½æ˜¯æ¨åŠ¨é¡¹ç›®å¿«é€Ÿå®Œæˆä¸»è¦åŠŸèƒ½ï¼Œé¿å…é™·å…¥æŠ€æœ¯ç»†èŠ‚çš„æ— é™ä¼˜åŒ–ã€‚

**æ ¸å¿ƒåŸåˆ™ï¼šåŠŸèƒ½ä¼˜å…ˆï¼Œç»†èŠ‚åç»­**

**ä½ çš„ä»»åŠ¡**ï¼š
1. å¿«é€Ÿè¯†åˆ«å½“å‰åŠŸèƒ½å®ŒæˆçŠ¶æ€
2. ç«‹å³æ¨åŠ¨ä¸‹ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½çš„å¼€å‘
3. é‡åˆ°é—®é¢˜æ—¶é€‰æ‹©æœ€ç®€å•ç›´æ¥çš„è§£å†³æ–¹æ¡ˆ
4. é¿å…è¿‡åº¦ä¼˜åŒ–å’Œå®Œç¾ä¸»ä¹‰é™·é˜±

**æ¨è¿›ç­–ç•¥**ï¼š
- å½“åŠŸèƒ½åŸºæœ¬å®Œæˆæ—¶ï¼šç«‹å³è½¬å‘ä¸‹ä¸€ä¸ªåŠŸèƒ½
- é‡åˆ°é”™è¯¯æ—¶ï¼šå¿«é€Ÿä¿®å¤ï¼Œä¸æ·±ç©¶åŸç†
- å‡ºç°æ€§èƒ½é—®é¢˜ï¼šå…ˆå¿½ç•¥ï¼Œé™¤éä¸¥é‡å½±å“ä½¿ç”¨
- ä»£ç ä¸å¤Ÿå®Œç¾ï¼šå…ˆèƒ½ç”¨ï¼Œåç»­è¿­ä»£

**å›å¤æ¨¡å¼**ï¼š
- "å¾ˆå¥½ï¼[åŠŸèƒ½å]å·²ç»åŸºæœ¬èƒ½ç”¨äº†ï¼Œç°åœ¨æˆ‘ä»¬ç«‹å³å¼€å§‹ä¸‹ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼š[ä¸‹ä¸€åŠŸèƒ½]"
- "è¿™ä¸ªé”™è¯¯ç”¨æœ€ç®€å•çš„æ–¹æ³•è§£å†³ï¼š[ç®€å•æ–¹æ¡ˆ]ï¼Œç„¶åç»§ç»­æ¨è¿›ä¸»åŠŸèƒ½"
- "å½“å‰è¿›å±•ä¸é”™ï¼Œè®©æˆ‘ä»¬ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½å®ç°ï¼Œç»†èŠ‚ä¼˜åŒ–ç•™åˆ°åé¢"

**ç»å¯¹é¿å…**ï¼š
- è¿‡åº¦åˆ†ææŠ€æœ¯ç»†èŠ‚
- çº ç»“äºä»£ç è´¨é‡é—®é¢˜
- æ— é™åˆ¶çš„æ€§èƒ½ä¼˜åŒ–
- å®Œç¾ä¸»ä¹‰çš„é‡æ„éœ€æ±‚

**ç›®æ ‡å¯¼å‘**ï¼š
ä½ çš„ç›®æ ‡æ˜¯è®©æ•´ä¸ªé¡¹ç›®å¿«é€Ÿè¾¾åˆ°"èƒ½ç”¨"çŠ¶æ€ï¼Œå½¢æˆå®Œæ•´çš„åŠŸèƒ½é—­ç¯ï¼Œè€Œä¸æ˜¯æ‰“é€ å®Œç¾çš„ä»£ç ã€‚

**å›å¤è¦æ±‚**ï¼š
- 100-200å­—ï¼Œç›´æ¥æ¨åŠ¨ä¸‹ä¸€æ­¥è¡ŒåŠ¨
- ä¸“æ³¨äºåŠŸèƒ½å®ç°è¿›åº¦
- ä¿æŒé«˜æ•ˆå¿«èŠ‚å¥
- ä½“ç°äº§å“æ€ç»´è€ŒéæŠ€æœ¯æ€ç»´
"""

            # å°†æˆªå›¾è½¬æ¢ä¸ºbase64
            screenshot_base64 = self.image_to_base64(screenshot)
            
            # æ£€æŸ¥cursor_replyä¸­æ˜¯å¦åŒ…å«GPT_VISION_REQUIREDæ ‡è®°
            vision_images = []
            cursor_reply_processed = cursor_reply
            
            # å¤„ç†GPT_VISION_REQUIREDæ ‡è®°
            if "GPT_VISION_REQUIRED:" in cursor_reply:
                lines = cursor_reply.split('\n')
                processed_lines = []
                
                for line in lines:
                    if "GPT_VISION_REQUIRED:" in line:
                        # æå–å›¾ç‰‡è·¯å¾„
                        try:
                            image_path = line.split("GPT_VISION_REQUIRED:")[1].strip()
                            if os.path.exists(image_path):
                                # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
                                from PIL import Image as PILImage
                                region_image = PILImage.open(image_path)
                                region_base64 = self.image_to_base64(region_image)
                                vision_images.append(region_base64)
                                processed_lines.append(f"[åŒºåŸŸå›¾ç‰‡] OCRè¯†åˆ«å¤±è´¥ï¼Œå·²æä¾›å›¾ç‰‡ä¾›è§†è§‰åˆ†æ")
                                logger.info(f"âœ… å·²æ·»åŠ åŒºåŸŸå›¾ç‰‡åˆ°GPT-4Oè§†è§‰åˆ†æ: {image_path}")
                            else:
                                processed_lines.append(f"[åŒºåŸŸå›¾ç‰‡] å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                        except Exception as e:
                            logger.error(f"å¤„ç†åŒºåŸŸå›¾ç‰‡å¤±è´¥: {e}")
                            processed_lines.append(line)
                    else:
                        processed_lines.append(line)
                
                cursor_reply_processed = '\n'.join(processed_lines)
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
            user_content = [
                {
                    "type": "text",
                    "text": f"""ä½œä¸ºäº§å“åŠŸèƒ½æ¨è¿›è€…ï¼Œè¯·åˆ†æCURSORçš„å›å¤å¹¶æ¨åŠ¨é¡¹ç›®å¿«é€Ÿå®Œæˆï¼š

**é¡¹ç›®çŠ¶æ€**ï¼š
{project_context[:400]}

**å½“å‰é˜¶æ®µ**ï¼š{current_stage}

**æœ€è¿‘è¿›å±•**ï¼š
{conversation_history[:600]}

**CURSORæœ€æ–°å›å¤**ï¼š
{cursor_reply_processed}

**æ¨è¿›ä»»åŠ¡**ï¼š
åŸºäºCURSORçš„å›å¤ï¼Œç«‹å³æ¨åŠ¨é¡¹ç›®å‘å‰å‘å±•ï¼Œé¿å…é™·å…¥æŠ€æœ¯ç»†èŠ‚ã€‚

**æ¨è¿›é‡ç‚¹**ï¼š
1. å¿«é€Ÿåˆ¤æ–­å½“å‰åŠŸèƒ½æ˜¯å¦åŸºæœ¬å¯ç”¨
2. å¦‚æœå¯ç”¨ï¼Œç«‹å³è½¬å‘ä¸‹ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½
3. å¦‚æœæœ‰é—®é¢˜ï¼Œé€‰æ‹©æœ€ç®€å•çš„è§£å†³æ–¹æ¡ˆ
4. æ˜ç¡®ä¸‹ä¸€æ­¥å…·ä½“è¦å®ç°çš„åŠŸèƒ½

**å›å¤è¦æ±‚**ï¼š
- 100-200å­—ï¼Œç›´æ¥æ¨åŠ¨è¡ŒåŠ¨
- ä¸“æ³¨äºåŠŸèƒ½å®Œæˆè¿›åº¦
- é¿å…æŠ€æœ¯ç»†èŠ‚çº ç»“
- ä½“ç°"å…ˆèƒ½ç”¨ï¼Œå†å®Œç¾"çš„äº§å“æ€ç»´

**ç«‹å³ç»™å‡ºæ¨è¿›æŒ‡ä»¤ï¼Œæ¨åŠ¨é¡¹ç›®å¿«é€Ÿå‰è¿›ï¼**"""
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{screenshot_base64}",
                        "detail": "high"
                    }
                }
            ]
            
            # æ·»åŠ é¢å¤–çš„åŒºåŸŸå›¾ç‰‡
            for region_base64 in vision_images:
                user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{region_base64}",
                        "detail": "high"
                    }
                })
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": product_manager_prompt
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ]
            
            # è°ƒç”¨GPT-4O
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=600,  # å¢åŠ tokené™åˆ¶ä»¥æ”¯æŒæ›´è¯¦ç»†çš„æŠ€æœ¯å›å¤
                temperature=0.3  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´å‡†ç¡®çš„æŠ€æœ¯å»ºè®®
            )
            
            # è·å–å›å¤å†…å®¹
            pm_reply = response.choices[0].message.content.strip()
            
            logger.info(f"GPT-4Oäº§å“ç»ç†å›å¤: {pm_reply[:100]}...")
            
            return pm_reply
            
        except Exception as e:
            logger.error(f"GPT-4OæŠ€æœ¯åˆ†æå¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªæŠ€æœ¯æ€§çš„fallbackå›å¤
            if "é”™è¯¯" in cursor_reply or "error" in cursor_reply.lower():
                return f"çœ‹åˆ°é”™è¯¯ä¿¡æ¯äº†ã€‚è®©æˆ‘ä»¬å…ˆåˆ†æä¸€ä¸‹é”™è¯¯çš„æ ¹æœ¬åŸå› ï¼Œç„¶ååˆ¶å®šå…·ä½“çš„ä¿®å¤æ–¹æ¡ˆã€‚è¯·æä¾›å®Œæ•´çš„é”™è¯¯å †æ ˆï¼Œè¿™æ ·æˆ‘å¯ä»¥å¸®ä½ å®šä½é—®é¢˜æ‰€åœ¨ã€‚"
            elif "å®Œæˆ" in cursor_reply or "å®ç°" in cursor_reply:
                return f"ä»£ç å®ç°å®Œæˆäº†ã€‚æ¥ä¸‹æ¥éœ€è¦éªŒè¯åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œå»ºè®®å…ˆè¿›è¡Œå•å…ƒæµ‹è¯•ï¼Œç„¶åæ£€æŸ¥è¾¹ç•Œæƒ…å†µå¤„ç†ã€‚æœ‰ä»€ä¹ˆéœ€è¦ä¼˜åŒ–çš„åœ°æ–¹å—ï¼Ÿ"
            else:
                return f"æ˜ç™½å½“å‰çš„æŠ€æœ¯çŠ¶å†µã€‚åŸºäº{current_stage}ï¼Œå»ºè®®æˆ‘ä»¬å…ˆç¡®è®¤æ ¸å¿ƒåŠŸèƒ½çš„å®ç°é€»è¾‘ï¼Œç„¶åé€æ­¥å®Œå–„ç»†èŠ‚ã€‚å…·ä½“çš„å®ç°æ–¹æ¡ˆä½ æœ‰ä»€ä¹ˆæƒ³æ³•ï¼Ÿ" 