#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å±å¹•ç›‘æ§æ¨¡å—
åŠŸèƒ½ï¼šæˆªå–å±å¹•ã€è¯†åˆ«æ–‡æœ¬ã€æ£€æµ‹UIå…ƒç´ 
"""

import asyncio
import cv2
import numpy as np
from PIL import Image, ImageGrab
import pyautogui
import psutil
import logging
import time
import io
import base64
from typing import Optional, Tuple, List
import subprocess
import platform

# å°è¯•å¯¼å…¥OCRå¼•æ“
EASYOCR_AVAILABLE = False
PYTESSERACT_AVAILABLE = False

try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    pass

try:
    import pytesseract
    PYTESSERACT_AVAILABLE = True
except ImportError:
    pass

logger = logging.getLogger(__name__)

class ScreenMonitor:
    """å±å¹•ç›‘æ§ç±»"""
    
    # ç±»çº§åˆ«çš„å…¨å±€OCRå¼•ç”¨ï¼Œä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
    _global_ocr_reader = None
    
    def __init__(self, selected_window_info: dict = None):
        self.ocr_reader = None
        self.use_easyocr = False
        self.last_screenshot = None
        self.cursor_window_coords = None
        self.selected_window_info = selected_window_info  # ç”¨æˆ·é€‰æ‹©çš„çª—å£ä¿¡æ¯
        
        # å¦‚æœæä¾›äº†é€‰å®šçš„çª—å£ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨
        if selected_window_info and 'position' in selected_window_info:
            x, y, width, height = selected_window_info['position']
            self.cursor_window_coords = (x, y, x + width, y + height)
            logger.info(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šçª—å£: {selected_window_info.get('title', 'Unknown')} at {self.cursor_window_coords}")
        
        # åˆå§‹åŒ–OCRå¼•æ“
        self._init_ocr()
        
        # é…ç½®pyautogui
        pyautogui.FAILSAFE = True
        pyautogui.PAUSE = 0.1
    
    def _init_ocr(self):
        """åˆå§‹åŒ–OCRå¼•æ“"""
        # å°è¯•EasyOCRä¼˜å…ˆ
        if EASYOCR_AVAILABLE:
            try:
                logger.info("ğŸ” æ­£åœ¨åˆå§‹åŒ–EasyOCRå¼•æ“...")
                self.ocr_reader = easyocr.Reader(['en', 'ch_sim'], gpu=False)  # ç¦ç”¨GPUä»¥é¿å…CUDAé—®é¢˜
                self.use_easyocr = True
                
                # è®¾ç½®å…¨å±€OCRå¼•ç”¨
                ScreenMonitor._global_ocr_reader = self.ocr_reader
                
                logger.info("âœ… EasyOCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
                return
            except Exception as e:
                logger.warning(f"âš ï¸ EasyOCRåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # å°è¯•Tesseract
        if PYTESSERACT_AVAILABLE:
            try:
                logger.info("ğŸ” æ­£åœ¨æµ‹è¯•Tesseractå¼•æ“...")
                from PIL import Image
                test_img = Image.new('RGB', (100, 30), color='white')
                pytesseract.image_to_string(test_img)
                logger.info("âœ… Tesseractå¼•æ“å¯ç”¨")
                return
            except Exception as e:
                logger.warning(f"âš ï¸ Tesseractä¸å¯ç”¨: {e}")
                logger.info("ğŸ’¡ å¦‚éœ€ä½¿ç”¨Tesseractï¼Œè¯·å‚è€ƒä»¥ä¸‹å®‰è£…æ–¹æ³•ï¼š")
                logger.info("   Windows: ä¸‹è½½å¹¶å®‰è£… https://github.com/UB-Mannheim/tesseract/wiki")
                logger.info("   ç„¶åè®¾ç½®ç¯å¢ƒå˜é‡ PATH åŒ…å« Tesseract å®‰è£…ç›®å½•")
        
        logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„OCRå¼•æ“ï¼Œæ–‡æœ¬æå–åŠŸèƒ½å°†è¢«ç¦ç”¨")
        logger.info("ğŸ’¡ æ¨èè§£å†³æ–¹æ¡ˆï¼š")
        logger.info("   1. å…³é—­æ‰€æœ‰Pythonç¨‹åºå’ŒIDE")
        logger.info("   2. ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œå‘½ä»¤è¡Œ")
        logger.info("   3. æ‰§è¡Œ: pip install easyocr")
        logger.info("   4. æˆ–è€…å®‰è£…Tesseract: https://github.com/UB-Mannheim/tesseract/wiki")
    
    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–æ–¹æ³•"""
        try:
            logger.info("ğŸš€ ScreenMonitoråˆå§‹åŒ–ä¸­...")
            
            # æ£€æŸ¥å±å¹•è®¿é—®æƒé™
            try:
                test_screenshot = pyautogui.screenshot()
                logger.info("âœ… å±å¹•è®¿é—®æƒé™æ­£å¸¸")
            except Exception as e:
                logger.warning(f"âš ï¸ å±å¹•è®¿é—®å¯èƒ½å—é™: {e}")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šçª—å£ï¼Œæ‰è‡ªåŠ¨æŸ¥æ‰¾CURSORçª—å£
            if not self.cursor_window_coords:
                cursor_coords = self.find_cursor_window()
                if cursor_coords:
                    logger.info(f"âœ… æ‰¾åˆ°CURSORçª—å£: {cursor_coords}")
                else:
                    logger.info("âš ï¸ æœªæ‰¾åˆ°CURSORçª—å£ï¼Œå°†ä½¿ç”¨å…¨å±æ¨¡å¼")
            else:
                logger.info(f"âœ… ä½¿ç”¨æŒ‡å®šCURSORçª—å£: {self.cursor_window_coords}")
            
            logger.info("âœ… ScreenMonitoråˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"ScreenMonitoråˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def capture_screenshot(self) -> Optional[Image.Image]:
        """æ•è·å±å¹•æˆªå›¾ - æ–°çš„ç»Ÿä¸€æ–¹æ³•"""
        try:
            # å¦‚æœæœ‰CURSORçª—å£åæ ‡ï¼Œä¼˜å…ˆæˆªå–è¯¥åŒºåŸŸ
            if self.cursor_window_coords:
                screenshot = ImageGrab.grab(bbox=self.cursor_window_coords)
            else:
                # å¦åˆ™æˆªå–å…¨å±
                screenshot = ImageGrab.grab()
            
            self.last_screenshot = screenshot
            return screenshot
            
        except Exception as e:
            logger.error(f"æˆªå–å±å¹•æ—¶å‡ºé”™: {e}")
            return None
    
    async def capture_cursor_window(self) -> Optional[Image.Image]:
        """æ•è·CURSORçª—å£æˆªå›¾"""
        try:
            # ä¼˜å…ˆä½¿ç”¨æŒ‡å®šçš„çª—å£åæ ‡
            cursor_coords = self.cursor_window_coords
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šçª—å£ï¼Œæ‰é‡æ–°æŸ¥æ‰¾
            if not cursor_coords:
                cursor_coords = self.find_cursor_window()
            
            if not cursor_coords:
                # å¦‚æœæ‰¾ä¸åˆ°CURSORçª—å£ï¼Œæˆªå–æ•´ä¸ªå±å¹•
                logger.info("æœªæ‰¾åˆ°CURSORçª—å£ï¼Œæˆªå–æ•´ä¸ªå±å¹•")
                screenshot = ImageGrab.grab()
            else:
                # æˆªå–æŒ‡å®šåŒºåŸŸ
                screenshot = ImageGrab.grab(bbox=cursor_coords)
                logger.debug(f"ğŸ“¸ æˆªå–çª—å£åŒºåŸŸ: {cursor_coords}")
            
            self.last_screenshot = screenshot
            
            # ä¿å­˜æˆªå›¾ç”¨äºè°ƒè¯•
            timestamp = int(time.time())
            debug_path = f"debug/screenshot_{timestamp}.png"
            screenshot.save(debug_path)
            logger.debug(f"æˆªå›¾å·²ä¿å­˜: {debug_path}")
            
            return screenshot
            
        except Exception as e:
            logger.error(f"æˆªå–çª—å£æ—¶å‡ºé”™: {e}")
            return None
    
    def find_cursor_window(self) -> Optional[Tuple[int, int, int, int]]:
        """æŸ¥æ‰¾CURSORçª—å£åæ ‡"""
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æŸ¥æ‰¾çª—å£
            if platform.system() == "Windows":
                return self._find_cursor_window_windows()
            else:
                return self._find_cursor_window_cross_platform()
                
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾CURSORçª—å£æ—¶å‡ºé”™: {e}")
            return None
    
    def _find_cursor_window_windows(self) -> Optional[Tuple[int, int, int, int]]:
        """åœ¨Windowsä¸ŠæŸ¥æ‰¾CURSORçª—å£"""
        try:
            import win32gui
            import win32con
            
            def enum_windows_callback(hwnd, windows):
                if win32gui.IsWindowVisible(hwnd):
                    window_title = win32gui.GetWindowText(hwnd)
                    if window_title and ("cursor" in window_title.lower() or "code" in window_title.lower()):
                        rect = win32gui.GetWindowRect(hwnd)
                        windows.append((window_title, rect))
                return True
            
            windows = []
            win32gui.EnumWindows(enum_windows_callback, windows)
            
            for title, rect in windows:
                if "cursor" in title.lower():
                    self.cursor_window_coords = rect
                    logger.info(f"æ‰¾åˆ°CURSORçª—å£: {title}")
                    return rect
            
            # å¦‚æœæ²¡æ‰¾åˆ°cursorï¼Œå°è¯•æ‰¾å…¶ä»–ç¼–è¾‘å™¨
            for title, rect in windows:
                if any(keyword in title.lower() for keyword in ["code", "vscode", "editor"]):
                    self.cursor_window_coords = rect
                    logger.info(f"æ‰¾åˆ°ç¼–è¾‘å™¨çª—å£: {title}")
                    return rect
                    
        except ImportError:
            logger.warning("win32guiä¸å¯ç”¨ï¼Œä½¿ç”¨pyautoguiæ–¹æ³•")
            
        return self._find_cursor_window_cross_platform()
    
    def _find_cursor_window_cross_platform(self) -> Optional[Tuple[int, int, int, int]]:
        """è·¨å¹³å°æ–¹å¼æŸ¥æ‰¾CURSORçª—å£"""
        try:
            # ä½¿ç”¨pyautoguiæŸ¥æ‰¾çª—å£
            window_titles = ["Cursor", "cursor", "Visual Studio Code", "Code"]
            
            for title in window_titles:
                try:
                    windows = pyautogui.getWindowsWithTitle(title)
                    if windows:
                        window = windows[0]
                        # å°è¯•æ¿€æ´»çª—å£
                        try:
                            window.activate()
                        except:
                            pass
                        
                        # è·å–çª—å£åæ ‡
                        left, top, width, height = window.left, window.top, window.width, window.height
                        self.cursor_window_coords = (left, top, left + width, top + height)
                        logger.info(f"æ‰¾åˆ°çª—å£: {title}")
                        return self.cursor_window_coords
                except Exception as e:
                    logger.debug(f"æŸ¥æ‰¾çª—å£ {title} å¤±è´¥: {e}")
                    continue
            
            logger.warning("æœªæ‰¾åˆ°CURSORæˆ–ç›¸å…³ç¼–è¾‘å™¨çª—å£")
            return None
            
        except Exception as e:
            logger.error(f"è·¨å¹³å°çª—å£æŸ¥æ‰¾å¤±è´¥: {e}")
            return None
    
    async def extract_text(self, image: Image.Image) -> str:
        """ä»å›¾åƒä¸­æå–æ–‡æœ¬ - ä¼˜åŒ–ç‰ˆæœ¬ï¼šå¢å¼ºfallbackæœºåˆ¶"""
        # å¦‚æœæ²¡æœ‰OCRå¼•æ“ï¼Œä½¿ç”¨æ™ºèƒ½å›¾åƒåˆ†æfallback
        if not EASYOCR_AVAILABLE and not PYTESSERACT_AVAILABLE:
            logger.debug("ğŸ’¡ ä½¿ç”¨æ™ºèƒ½å›¾åƒåˆ†æä»£æ›¿OCR")
            return await self.intelligent_text_fallback(image)
            
        try:
            # é¢„å¤„ç†å›¾åƒä»¥æé«˜OCRå‡†ç¡®æ€§
            processed_image = self.preprocess_image(image)
            
            if self.use_easyocr and self.ocr_reader:
                # ä½¿ç”¨EasyOCRè¿›è¡Œæ–‡æœ¬è¯†åˆ«
                logger.debug("ğŸ” ä½¿ç”¨EasyOCRæå–æ–‡æœ¬...")
                result = self.ocr_reader.readtext(np.array(processed_image))
                
                # æå–æ–‡æœ¬å†…å®¹
                extracted_text = ' '.join([detection[1] for detection in result if detection[2] > 0.5])
                logger.debug(f"ğŸ“ EasyOCRæå–åˆ°æ–‡æœ¬: {extracted_text[:100]}...")
                
                return extracted_text
            
            elif PYTESSERACT_AVAILABLE:
                # ä½¿ç”¨Tesseractè¿›è¡Œæ–‡æœ¬è¯†åˆ«
                logger.debug("ğŸ” ä½¿ç”¨Tesseractæå–æ–‡æœ¬...")
                extracted_text = pytesseract.image_to_string(processed_image, lang='eng+chi_sim')
                logger.debug(f"ğŸ“ Tesseractæå–åˆ°æ–‡æœ¬: {extracted_text[:100]}...")
                
                return extracted_text.strip()
            
            else:
                logger.debug("âŒ æ²¡æœ‰å¯ç”¨çš„OCRå¼•æ“")
                return await self.intelligent_text_fallback(image)
                
        except Exception as e:
            logger.warning(f"âš ï¸ OCRæ–‡æœ¬æå–å¤±è´¥: {e}")
            return await self.intelligent_text_fallback(image)
    
    async def intelligent_text_fallback(self, image: Image.Image) -> str:
        """æ™ºèƒ½å›¾åƒåˆ†æfallback - å½“OCRä¸å¯ç”¨æ—¶çš„æ›¿ä»£æ–¹æ¡ˆ"""
        try:
            # åŸºäºå›¾åƒç‰¹å¾åˆ†ææ¨æ–­å¯èƒ½çš„çŠ¶æ€
            img_array = np.array(image)
            height, width = img_array.shape[:2]
            
            # åˆ†æå›¾åƒç‰¹å¾
            features = {
                "has_bright_areas": self.detect_bright_areas(img_array),
                "has_color_patterns": self.detect_color_patterns(img_array),
                "has_ui_elements": self.detect_basic_ui_elements(img_array),
                "bottom_area_activity": self.analyze_bottom_area(img_array)
            }
            
            # æ ¹æ®ç‰¹å¾æ¨æ–­å¯èƒ½çš„æ–‡æœ¬å†…å®¹
            inferred_text = self.infer_text_from_features(features)
            
            logger.debug(f"ğŸ’¡ æ™ºèƒ½åˆ†ææ¨æ–­: {inferred_text}")
            return inferred_text
            
        except Exception as e:
            logger.debug(f"æ™ºèƒ½fallbackåˆ†æå¤±è´¥: {e}")
            return "ç•Œé¢æˆªå›¾å·²è·å–ï¼ŒOCRåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨"
    
    def detect_bright_areas(self, img_array) -> bool:
        """æ£€æµ‹æ˜äº®åŒºåŸŸï¼ˆå¯èƒ½æ˜¯å¯¹è¯æ¡†æˆ–é€šçŸ¥ï¼‰"""
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        bright_pixels = np.sum(gray > 200)
        total_pixels = gray.shape[0] * gray.shape[1]
        bright_ratio = bright_pixels / total_pixels
        return bright_ratio > 0.3
    
    def detect_color_patterns(self, img_array) -> dict:
        """æ£€æµ‹é¢œè‰²æ¨¡å¼"""
        # è®¡ç®—ä¸»è¦é¢œè‰²
        colors = {}
        for channel in range(3):
            mean_val = np.mean(img_array[:, :, channel])
            colors[['red', 'green', 'blue'][channel]] = mean_val
        
        # æ£€æµ‹å¯èƒ½çš„çŠ¶æ€é¢œè‰²
        has_green = colors['green'] > 150 and colors['green'] > colors['red'] * 1.2
        has_red = colors['red'] > 150 and colors['red'] > colors['green'] * 1.2
        has_blue = colors['blue'] > 150
        
        return {
            "success_colors": has_green,
            "error_colors": has_red,
            "info_colors": has_blue,
            "dominant_color": max(colors, key=colors.get)
        }
    
    def detect_basic_ui_elements(self, img_array) -> dict:
        """æ£€æµ‹åŸºæœ¬UIå…ƒç´ """
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
        
        # æ£€æµ‹çŸ©å½¢ï¼ˆå¯èƒ½æ˜¯æŒ‰é’®æˆ–å¯¹è¯æ¡†ï¼‰
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        rectangles = []
        
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            if w > 50 and h > 20 and w/h > 2:  # å¯èƒ½æ˜¯æŒ‰é’®
                rectangles.append((x, y, w, h))
        
        return {
            "edge_density": edge_density,
            "button_like_elements": len(rectangles),
            "has_structure": edge_density > 0.1
        }
    
    def analyze_bottom_area(self, img_array) -> dict:
        """åˆ†æåº•éƒ¨åŒºåŸŸï¼ˆé€šå¸¸æ˜¯è¾“å…¥æˆ–çŠ¶æ€åŒºåŸŸï¼‰"""
        height = img_array.shape[0]
        bottom_area = img_array[int(height * 0.8):, :]  # åº•éƒ¨20%
        
        # åˆ†æåº•éƒ¨åŒºåŸŸçš„é¢œè‰²å’Œäº®åº¦
        bottom_mean = np.mean(bottom_area, axis=(0, 1))
        bottom_brightness = np.mean(bottom_mean)
        
        # æ£€æµ‹åº•éƒ¨æ˜¯å¦æœ‰æ´»åŠ¨ï¼ˆé¢œè‰²å˜åŒ–ï¼‰
        bottom_std = np.std(bottom_area, axis=(0, 1))
        has_activity = np.mean(bottom_std) > 20
        
        return {
            "brightness": bottom_brightness,
            "has_activity": has_activity,
            "is_bright": bottom_brightness > 150
        }
    
    def infer_text_from_features(self, features: dict) -> str:
        """æ ¹æ®å›¾åƒç‰¹å¾æ¨æ–­å¯èƒ½çš„æ–‡æœ¬å†…å®¹"""
        inferences = []
        
        # æ ¹æ®é¢œè‰²æ¨¡å¼æ¨æ–­
        if features.get("has_color_patterns", {}).get("success_colors"):
            inferences.append("æ£€æµ‹åˆ°æˆåŠŸçŠ¶æ€æŒ‡ç¤ºå™¨")
        
        if features.get("has_color_patterns", {}).get("error_colors"):
            inferences.append("æ£€æµ‹åˆ°é”™è¯¯çŠ¶æ€æŒ‡ç¤ºå™¨")
        
        # æ ¹æ®UIå…ƒç´ æ¨æ–­
        if features.get("has_ui_elements", {}).get("button_like_elements", 0) > 0:
            inferences.append("æ£€æµ‹åˆ°äº¤äº’å¼UIå…ƒç´ ")
        
        # æ ¹æ®åº•éƒ¨åŒºåŸŸæ¨æ–­
        if features.get("bottom_area_activity", {}).get("has_activity"):
            inferences.append("åº•éƒ¨åŒºåŸŸæœ‰æ´»åŠ¨ï¼Œå¯èƒ½æ˜¯è¾“å…¥åŒºåŸŸ")
        
        # æ ¹æ®äº®åº¦æ¨æ–­
        if features.get("has_bright_areas"):
            inferences.append("æ£€æµ‹åˆ°é«˜äº®åŒºåŸŸï¼Œå¯èƒ½æ˜¯å¯¹è¯æ¡†æˆ–é€šçŸ¥")
        
        if not inferences:
            return "å›¾åƒå·²åˆ†æï¼Œç­‰å¾…è¿›ä¸€æ­¥æ“ä½œ"
        
        return " | ".join(inferences)
    
    def preprocess_image(self, image: Image.Image) -> Image.Image:
        """é¢„å¤„ç†å›¾åƒä»¥æé«˜OCRå‡†ç¡®æ€§"""
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            img_array = np.array(image)

            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)

            # æ”¾å¤§å›¾åƒä»¥æå‡å°å­—ä½“è¯†åˆ«ç‡
            gray = cv2.resize(gray, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_LINEAR)

            # åŒè¾¹æ»¤æ³¢ä¿ç•™è¾¹ç¼˜åŒæ—¶å»å™ª
            filtered = cv2.bilateralFilter(gray, 9, 75, 75)

            # è‡ªé€‚åº”é˜ˆå€¼å¤„ç†
            thresh = cv2.adaptiveThreshold(
                filtered, 255,
                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY, 31, 2
            )

            # å½¢æ€å­¦æ“ä½œè¿›ä¸€æ­¥å»å™ª
            kernel = np.ones((2, 2), np.uint8)
            morphed = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
            morphed = cv2.morphologyEx(morphed, cv2.MORPH_CLOSE, kernel)

            # è½¬æ¢å›PIL Image
            processed_image = Image.fromarray(morphed)

            return processed_image
            
        except Exception as e:
            logger.error(f"å›¾åƒé¢„å¤„ç†æ—¶å‡ºé”™: {e}")
            return image
    
    def get_screenshot_base64(self, image: Image.Image) -> str:
        """å°†æˆªå›¾è½¬æ¢ä¸ºbase64ç¼–ç """
        try:
            buffer = io.BytesIO()
            image.save(buffer, format='PNG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            return img_base64
        except Exception as e:
            logger.error(f"è½¬æ¢base64æ—¶å‡ºé”™: {e}")
            return ""
    
    async def capture_dialog_area(self) -> Optional[Image.Image]:
        """æ•è·å¯¹è¯æ¡†åŒºåŸŸ"""
        try:
            full_screenshot = await self.capture_cursor_window()
            if not full_screenshot:
                return None
            
            # åˆ†ææˆªå›¾ï¼Œå®šä½å¯¹è¯æ¡†åŒºåŸŸ
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„å›¾åƒåˆ†æé€»è¾‘
            # æš‚æ—¶è¿”å›å³ä¾§å¯¹è¯åŒºåŸŸï¼ˆå‡è®¾æ˜¯å±å¹•çš„å³åŠéƒ¨åˆ†ï¼‰
            width, height = full_screenshot.size
            dialog_area = full_screenshot.crop((width//2, 0, width, height))
            
            return dialog_area
            
        except Exception as e:
            logger.error(f"æ•è·å¯¹è¯æ¡†åŒºåŸŸæ—¶å‡ºé”™: {e}")
            return None
    
    def detect_ui_elements(self, image: Image.Image) -> dict:
        """æ£€æµ‹UIå…ƒç´ ï¼ˆæŒ‰é’®ã€è¾“å…¥æ¡†ç­‰ï¼‰"""
        try:
            # ä½¿ç”¨OpenCVæ£€æµ‹UIå…ƒç´ 
            img_array = np.array(image)
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            
            # æ£€æµ‹æŒ‰é’®ï¼ˆå‡è®¾æ˜¯çŸ©å½¢åŒºåŸŸï¼‰
            edges = cv2.Canny(gray, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            ui_elements = {
                'buttons': [],
                'input_fields': [],
                'text_areas': []
            }
            
            for contour in contours:
                # è®¡ç®—è½®å»“é¢ç§¯å’Œè¾¹ç•Œæ¡†
                area = cv2.contourArea(contour)
                if area > 1000:  # è¿‡æ»¤æ‰å¤ªå°çš„åŒºåŸŸ
                    x, y, w, h = cv2.boundingRect(contour)
                    
                    # æ ¹æ®å®½é«˜æ¯”åˆ¤æ–­å…ƒç´ ç±»å‹
                    aspect_ratio = w / h
                    if 2 <= aspect_ratio <= 6:  # å¯èƒ½æ˜¯æŒ‰é’®
                        ui_elements['buttons'].append((x, y, w, h))
                    elif aspect_ratio > 6:  # å¯èƒ½æ˜¯è¾“å…¥æ¡†
                        ui_elements['input_fields'].append((x, y, w, h))
            
            return ui_elements
            
        except Exception as e:
            logger.error(f"æ£€æµ‹UIå…ƒç´ æ—¶å‡ºé”™: {e}")
            return {}
    
    async def save_screenshot(self, image: Image.Image, filename: str) -> str:
        """ä¿å­˜æˆªå›¾"""
        try:
            filepath = f"screenshots/{filename}"
            image.save(filepath)
            logger.info(f"æˆªå›¾å·²ä¿å­˜: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"ä¿å­˜æˆªå›¾æ—¶å‡ºé”™: {e}")
            return ""
    
    def get_ocr_status(self) -> dict:
        """è·å–OCRå¼•æ“çŠ¶æ€"""
        return {
            "easyocr_available": EASYOCR_AVAILABLE,
            "pytesseract_available": PYTESSERACT_AVAILABLE,
            "current_engine": "EasyOCR" if self.use_easyocr else "Tesseract" if PYTESSERACT_AVAILABLE else "None",
            "ocr_reader_initialized": self.ocr_reader is not None
        }
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            logger.info("ğŸ§¹ æ¸…ç†ScreenMonitorèµ„æº...")
            
            # æ¸…ç†OCRå¼•æ“èµ„æº
            if self.ocr_reader:
                self.ocr_reader = None
                
            # æ¸…ç†æˆªå›¾ç¼“å­˜
            self.last_screenshot = None
            
            logger.info("âœ… ScreenMonitorèµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†ScreenMonitorèµ„æºæ—¶å‡ºé”™: {e}") 